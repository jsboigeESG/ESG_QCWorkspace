{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n","<hr>"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["# Importer les bibliothèques nécessaires\n","from AlgorithmImports import *\n","import numpy as np\n","import pandas as pd\n","import statsmodels.api as sm\n","from arch.unitroot.cointegration import engle_granger\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Initialiser QuantBook\n","qb = QuantBook()\n","\n","# Sélectionner les ETFs sectoriels\n","sector_etfs = [\"XLF\", \"XLK\", \"XLE\", \"XLY\", \"XLP\", \"XLI\", \"XLV\", \"XLU\", \"XLRE\", \"XLC\", \"XLB\"]\n","symbols = [qb.AddEquity(etf, Resolution.Daily).Symbol for etf in sector_etfs]\n","\n","# Obtenir les données historiques (2 ans)\n","history = qb.History(symbols, 500, Resolution.Daily)\n","\n","# Préparer les données\n","prices = history.close.unstack(level=0)\n","\n","# ** Étape 1 : Matrice de corrélation **\n","# Calculer les rendements quotidiens\n","daily_returns = prices.pct_change().dropna()\n","\n","# Calculer la matrice de corrélation\n","correlation_matrix = daily_returns.corr()\n","\n","# Afficher la matrice de corrélation sous forme de carte thermique\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar=True)\n","plt.title(\"Matrice de corrélation des rendements quotidiens\")\n","plt.show()\n","\n","# ** Étape 2 : Tester la co-intégration entre deux ETFs **\n","etf1 = \"XLK\"  # Exemple ETF 1 (Technologie)\n","etf2 = \"XLY\"  # Exemple ETF 2 (Consommation discrétionnaire)\n","\n","# Extraire les prix des deux ETFs\n","etf1_prices = prices[etf1].dropna()\n","etf2_prices = prices[etf2].dropna()\n","\n","# Vérifier la co-intégration avec Engle-Granger\n","model = engle_granger(etf1_prices, etf2_prices, trend=\"n\", lags=0)\n","print(f\"P-valeur du test de co-intégration entre {etf1} et {etf2} : {model.pvalue}\")\n","\n","# Calculer les coefficients de co-intégration via une régression\n","X = sm.add_constant(etf2_prices)\n","regression = sm.OLS(etf1_prices, X).fit()\n","\n","# Récupérer les coefficients\n","beta0 = regression.params[0]  # Constante\n","beta1 = regression.params[1]  # Coefficient du second ETF\n","\n","# Calculer le spread\n","spread = etf1_prices - (beta0 + beta1 * etf2_prices)\n","\n","# Visualiser les prix et les écarts\n","plt.figure(figsize=(14, 7))\n","\n","# Visualisation des prix\n","plt.subplot(2, 1, 1)\n","plt.plot(etf1_prices, label=f\"Prix de {etf1}\")\n","plt.plot(etf2_prices, label=f\"Prix ajusté de {etf2}\")\n","plt.title(\"Prix des ETFs\")\n","plt.legend()\n","\n","# Visualisation du spread\n","plt.subplot(2, 1, 2)\n","plt.plot(spread, label=\"Écart (spread)\")\n","plt.axhline(spread.mean(), color='red', linestyle='--', label='Moyenne du spread')\n","plt.title(f\"Spread entre {etf1} et {etf2}\")\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":2,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from itertools import combinations\n","# Ajouter un filtre basé sur la volatilité moyenne et le volume\n","def filter_pairs(prices, threshold=0.05):\n","    filtered_results = []\n","    for etf1, etf2 in combinations(prices.columns, 2):\n","        etf1_prices, etf2_prices = prices[etf1].dropna(), prices[etf2].dropna()\n","        if len(etf1_prices) == len(etf2_prices):\n","            model = engle_granger(etf1_prices, etf2_prices, trend=\"n\", lags=0)\n","            if model.pvalue < threshold:\n","                volatility = etf1_prices.pct_change().std() + etf2_prices.pct_change().std()\n","                avg_volume = prices[[etf1, etf2]].mean(axis=0).mean()\n","                filtered_results.append((etf1, etf2, model.pvalue, volatility, avg_volume))\n","    return pd.DataFrame(filtered_results, columns=[\"ETF1\", \"ETF2\", \"P-Value\", \"Volatility\", \"Avg Volume\"])\n","\n","filtered_pairs = filter_pairs(prices, threshold=0.05)\n","print(filtered_pairs.sort_values(by=\"P-Value\"))\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Recalibrer la détection de paires\n","\n","Dans cette première étape, nous allons réutiliser notre fonction `filter_pairs` pour détecter des paires co-intégrées, mais nous allons rendre les conditions **un peu moins strictes** que celles introduites récemment. Notamment :\n","- Nous allons fixer un seuil de p-value un peu plus élevé (0.10 au lieu de 0.05).\n","- Nous allons enlever la contrainte de `corr > 0.8` (ou la rendre optionnelle).\n","- Nous allons nous assurer que la taille de la période est suffisante (par exemple 500 barres daily).\n","\n","Ensuite, nous observerons la liste des paires retenues pour voir lesquelles sont vraiment prometteuses.\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from itertools import combinations\n","import pandas as pd\n","from arch.unitroot.cointegration import engle_granger\n","\n","def filter_pairs_recalibrated(prices, pval_threshold=0.10):\n","    \"\"\"\n","    Identique à filter_pairs, mais avec un p-val threshold un peu moins restrictif.\n","    \"\"\"\n","    results = []\n","    for etf1, etf2 in combinations(prices.columns, 2):\n","        etf1_prices = prices[etf1].dropna()\n","        etf2_prices = prices[etf2].dropna()\n","        if len(etf1_prices) == len(etf2_prices) and len(etf1_prices) > 50:\n","            model = engle_granger(etf1_prices, etf2_prices, trend=\"n\", lags=0)\n","            if model.pvalue < pval_threshold:\n","                # On pourrait ajouter un test de corrélation si on le souhaite\n","                # corr = etf1_prices.pct_change().corr(etf2_prices.pct_change())\n","                results.append(\n","                    (etf1, etf2, \n","                     model.pvalue)\n","                )\n","    df = pd.DataFrame(results, columns=[\"ETF1\", \"ETF2\", \"P-Value\"])\n","    return df.sort_values(by=\"P-Value\")\n","\n","# Recalibrons la liste des paires\n","filtered_pairs_looser = filter_pairs_recalibrated(prices, pval_threshold=0.10)\n","filtered_pairs_looser\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Test de co-intégration glissant (rolling Engle-Granger)\n","\n","Pour être plus robuste, nous allons tester la co-intégration sur une *fenêtre mobile* (rolling window) plutôt que sur l’intégralité de la période. Ainsi, nous vérifions si la relation reste stationnaire au fil du temps. Nous allons illustrer cette approche sur la paire `XLF–XLK` (ou celle de notre choix dans la liste filtrée).\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","def rolling_cointegration_test(seriesA, seriesB, window=100, p_threshold=0.10):\n","    \"\"\"\n","    Applique le test Engle-Granger sur des fenêtres mobiles.\n","    Renvoie un pd.Series des p-values, indexées par la date de fin de la fenêtre.\n","    \"\"\"\n","    p_values = []\n","    index_vals = seriesA.index\n","    for i in range(window, len(seriesA)):\n","        # Fenêtre [i-window : i]\n","        A_window = seriesA.iloc[i-window:i]\n","        B_window = seriesB.iloc[i-window:i]\n","        model = engle_granger(A_window, B_window, trend=\"n\", lags=0)\n","        p_values.append(model.pvalue)\n","    # Index des p-values = dates de la fin de la fenêtre\n","    return pd.Series(p_values, index=index_vals[window:])\n","\n","# Choix d'une paire (ex. \"XLF–XLK\") selon la liste filtrée\n","etfA, etfB = \"XLF\", \"XLK\"\n","\n","A_prices = prices[etfA].dropna()\n","B_prices = prices[etfB].dropna()\n","\n","roll_pvals = rolling_cointegration_test(A_prices, B_prices, window=100, p_threshold=0.10)\n","\n","plt.figure(figsize=(10,4))\n","roll_pvals.plot()\n","plt.axhline(0.10, color='red', linestyle='--', label='Threshold 0.10')\n","plt.title(f\"P-values Engle-Granger rolling (fenêtre=100) pour {etfA}-{etfB}\")\n","plt.legend()\n","plt.show()\n","\n","roll_pvals.describe()\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Génération de signaux via z-score sur le spread\n","\n","Nous allons ici implémenter une fonction qui, pour deux séries de prix (A, B), calcule en rolling:\n","- Une régression (A ~ B) pour obtenir le coefficient β\n","- Le spread = A - β * B\n","- Le z-score = (spread - mean(spread)) / std(spread)\n","\n","Nous fixerons un lookback (ex. 30 barres) pour calculer la moyenne et l’écart-type du spread, et un *threshold* (ex. ±1.5 ou ±2) pour générer des signaux LONG/SHORT.\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import statsmodels.api as sm\n","\n","def compute_signals_zscore(seriesA, seriesB, window=30, z_threshold=1.5):\n","    \"\"\"\n","    Calcule un spread rolling + z-score, et renvoie un DataFrame\n","    avec les colonnes: ['spread', 'zscore', 'signal'].\n","    signal = +1 => LONG A / SHORT B\n","    signal = -1 => SHORT A / LONG B\n","    \"\"\"\n","    # Assurons-nous qu'on a les mêmes dates\n","    common_index = seriesA.index.intersection(seriesB.index)\n","    A = seriesA.loc[common_index].copy()\n","    B = seriesB.loc[common_index].copy()\n","    \n","    results = []\n","    \n","    # Rolling approach\n","    for i in range(window, len(A)):\n","        # Fenêtre [i-window : i]\n","        A_win = A.iloc[i-window:i]\n","        B_win = B.iloc[i-window:i]\n","        \n","        # OLS pour estimer A ~ B\n","        X = sm.add_constant(B_win)\n","        reg = sm.OLS(A_win, X).fit()\n","        beta0 = reg.params.iloc[0]\n","        beta1 = reg.params.iloc[1]\n","\n","        \n","        spread_arr = (A_win - (beta0 + beta1 * B_win))\n","        # Dernier point (barre i-1) => on l'utilise pour le signal\n","        spread_values = spread_arr.values\n","        spread_mean = np.mean(spread_values)\n","        spread_std = np.std(spread_values) if np.std(spread_values) != 0 else 1e-9\n","        \n","        # Spread actuel = A[i] - (beta0 + beta1*B[i])\n","        current_spread = A.iloc[i] - (beta0 + beta1 * B.iloc[i])\n","        zscore = (current_spread - spread_mean) / spread_std\n","        \n","        # Génération du signal\n","        if zscore > z_threshold:\n","            signal = -1  # SHORT A, LONG B\n","        elif zscore < -z_threshold:\n","            signal = +1  # LONG A, SHORT B\n","        else:\n","            signal = 0\n","        \n","        results.append((A.index[i], current_spread, zscore, signal))\n","    \n","    df_signals = pd.DataFrame(results, columns=[\"Date\", \"Spread\", \"Zscore\", \"Signal\"])\n","    df_signals.set_index(\"Date\", inplace=True)\n","    return df_signals\n","\n","df_z = compute_signals_zscore(A_prices, B_prices, window=30, z_threshold=1.5)\n","\n","plt.figure(figsize=(10,5))\n","df_z['Zscore'].plot()\n","plt.axhline(1.5, color='red', linestyle='--', label='+Threshold')\n","plt.axhline(-1.5, color='red', linestyle='--', label='-Threshold')\n","plt.title(f\"Z-score rolling (win=30) pour {etfA}-{etfB}\")\n","plt.legend()\n","plt.show()\n","\n","df_z['Signal'].value_counts()\n"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Mini backtest manuel sur la paire (A, B)\n","\n","Nous allons simuler un PnL théorique en supposant qu’à chaque dépassement de z-score (+1 ou -1), on ouvre une position A/B inversée, et on la ferme quand le z-score revient vers 0.\n","\n","Ceci reste un backtest artisanal, juste pour valider la logique. Pour aller plus loin, nous pourrions l’intégrer à QuantConnect (avec OnData, OnEndOfDay, etc.).\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def mini_backtest(df_signals, seriesA, seriesB, capital=100000):\n","    \"\"\"\n","    Hypothèse : \n","      - On entre en position quand signal passe de 0 à +1/-1\n","      - On sort quand signal repasse à 0\n","      - On achète/vend un nominal fixe (ex. on alloue 50% capital à A, 50% à B en sens inverse).\n","    Simplifié à l'extrême, sans considération de frais, slippage, etc.\n","    \"\"\"\n","    # On remerge les prix dans df_signals\n","    df_bt = pd.DataFrame({\n","        'Signal': df_signals['Signal'],\n","        'PriceA': seriesA[df_signals.index],\n","        'PriceB': seriesB[df_signals.index]\n","    }).dropna()\n","    \n","    positions = []  # Stocke les positions pour éviter SettingWithCopyWarning\n","    pnls = []       # Stocke les PnL cumulés\n","    current_position = 0  # Position actuelle : 0, +1, ou -1\n","    \n","    # Variables de tracking\n","    entry_priceA = 0\n","    entry_priceB = 0\n","    cum_pnl = 0.0  # PnL cumulatif\n","\n","    # Parcours des lignes du DataFrame\n","    for i in range(len(df_bt)):\n","        signal_curr = df_bt['Signal'].iloc[i]\n","        priceA_curr = df_bt['PriceA'].iloc[i]\n","        priceB_curr = df_bt['PriceB'].iloc[i]\n","\n","        # Vérifie si le signal change\n","        if signal_curr != current_position:\n","            # Fermer la position actuelle\n","            if current_position != 0:\n","                if current_position == +1:\n","                    # LONG A, SHORT B\n","                    trade_pnl = (priceA_curr - entry_priceA) - (priceB_curr - entry_priceB)\n","                else:\n","                    # SHORT A, LONG B\n","                    trade_pnl = -(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB)\n","                \n","                cum_pnl += trade_pnl\n","            \n","            # Ouvrir la nouvelle position\n","            current_position = signal_curr\n","            if current_position != 0:  # Enregistre les prix d'entrée\n","                entry_priceA = priceA_curr\n","                entry_priceB = priceB_curr\n","        \n","        # Ajoute les valeurs actuelles aux listes\n","        positions.append(current_position)\n","        pnls.append(cum_pnl)\n","\n","    # Ajout des colonnes au DataFrame\n","    df_bt['Position'] = positions\n","    df_bt['PnL'] = pnls\n","\n","    return df_bt\n","\n","df_bt_results = mini_backtest(df_z, A_prices, B_prices)\n","df_bt_results.tail(20)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualisation des résultats du mini-backtest"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,4))\n","df_bt_results['PnL'].plot()\n","plt.title(\"Évolution du PnL théorique (mini-backtest artisanal)\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Filtrer la prise de position avec la p-value rolling\n","\n","Nous allons ici modifier la fonction `compute_signals_zscore` pour inclure aussi la rolling p-value. L'idée est de :\n","1. Calculer la p-value sur la même fenêtre (ou sur une fenêtre plus longue).\n","2. N'autoriser le trade que si p-value < 0.10 (ou un autre seuil).\n","3. Conserver le z-score pour déclencher le signal ±2.\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def compute_signals_with_pval(seriesA, seriesB, window=30, z_threshold=2.0, p_threshold=0.10):\n","    \"\"\"\n","    Calcule le z-score comme avant, mais intègre une rolling p-value\n","    et on ne génère un signal que si la p-value < p_threshold.\n","    \"\"\"\n","    common_index = seriesA.index.intersection(seriesB.index)\n","    A = seriesA.loc[common_index].copy()\n","    B = seriesB.loc[common_index].copy()\n","    \n","    # Pour la rolling p-value, on peut utiliser la même fenêtre ou un plus grand\n","    # ex. fenetre de 60 ou 100 barres\n","    window_pval = max(window, 60)\n","    \n","    signals_data = []\n","    \n","    for i in range(window_pval, len(A)):\n","        # Fenêtre [i-window_pval : i]\n","        A_win = A.iloc[i-window_pval:i]\n","        B_win = B.iloc[i-window_pval:i]\n","        \n","        # Test Engle-Granger sur ce segment\n","        model = engle_granger(A_win, B_win, trend='n', lags=0)\n","        pval = model.pvalue\n","        \n","        # Ensuite, régression pour le z-score\n","        X = sm.add_constant(B_win)\n","        reg = sm.OLS(A_win, X).fit()\n","        beta0 = reg.params.iloc[0]\n","        beta1 = reg.params.iloc[1]\n","        \n","        # On se base maintenant sur la dernière sous-fenêtre \"window\" (plus court) pour le z-score\n","        shortA = A.iloc[i-window:i]\n","        shortB = B.iloc[i-window:i]\n","        \n","        # Spread dans la sous-fenêtre\n","        spread_arr = shortA - (beta0 + beta1*shortB)\n","        spread_mean = spread_arr.mean()\n","        spread_std = spread_arr.std() if spread_arr.std() != 0 else 1e-9\n","        \n","        current_spread = A.iloc[i] - (beta0 + beta1 * B.iloc[i])\n","        zscore = (current_spread - spread_mean)/spread_std\n","        \n","        # Condition : pval < p_threshold et |zscore| > z_threshold => signal\n","        if pval < p_threshold:\n","            if zscore > z_threshold:\n","                signal = -1\n","            elif zscore < -z_threshold:\n","                signal = +1\n","            else:\n","                signal = 0\n","        else:\n","            signal = 0\n","        \n","        signals_data.append((A.index[i], pval, current_spread, zscore, signal))\n","    \n","    df_signals = pd.DataFrame(signals_data, columns=[\"Date\",\"Pval\",\"Spread\",\"Zscore\",\"Signal\"])\n","    df_signals.set_index(\"Date\", inplace=True)\n","    return df_signals\n","\n","df_signals_pv = compute_signals_with_pval(A_prices, B_prices, window=30, z_threshold=2, p_threshold=0.10)\n","df_signals_pv.tail(10)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Mini backtest (p-value + z-score)\n","\n","Nous réutilisons la fonction de backtest basique, mais appliquée à la DataFrame `df_signals_pv`. L'objectif est de voir si la prise en compte de la co-intégration au moment de l'entrée améliore ou non le résultat final.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_bt_pv = mini_backtest(df_signals_pv, A_prices, B_prices)\n","df_bt_pv['PnL'].plot(figsize=(10,4), title=\"PnL cumulatif (co-intégration + z-score)\")\n","plt.show()\n","\n","df_bt_pv.tail(10)\n"]},{"cell_type":"markdown","metadata":{},"source":["### A) Comparaison de différents z-score thresholds\n","\n","Nous allons définir une fonction permettant de faire varier les paramètres de notre stratégie (z-score threshold) afin de comparer l'impact sur le PnL. L'idée est de boucler sur plusieurs valeurs (par exemple 1.5, 1.8, 2.0, 2.2) et d'afficher un résumé des résultats ou un graphique comparatif.\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def test_different_zscore_thresholds(seriesA, seriesB, thresholds=[1.5, 1.8, 2.0, 2.2], p_threshold=0.10):\n","    \"\"\"\n","    Boucle sur plusieurs valeurs de z-score threshold.\n","    Pour chaque threshold, on génère df_signals puis on backteste.\n","    Retourne un DataFrame résumant le PnL final.\n","    \"\"\"\n","    results = []\n","    for thr in thresholds:\n","        df_signals_pv = compute_signals_with_pval(\n","            seriesA, seriesB, \n","            window=30, \n","            z_threshold=thr, \n","            p_threshold=p_threshold\n","        )\n","        df_bt_pv = mini_backtest(df_signals_pv, seriesA, seriesB)\n","        final_pnl = df_bt_pv['PnL'].iloc[-1] if len(df_bt_pv) > 0 else 0\n","        results.append((thr, final_pnl))\n","    \n","    return pd.DataFrame(results, columns=[\"ZScoreThreshold\", \"FinalPnL\"])\n","\n","threshold_values = [1.5, 1.8, 2.0, 2.2]\n","df_threshold_test = test_different_zscore_thresholds(A_prices, B_prices, threshold_values, p_threshold=0.10)\n","df_threshold_test\n"]},{"cell_type":"markdown","metadata":{},"source":["### B) Test sur plusieurs paires en parallèle\n","\n","Pour aller plus loin, nous allons appliquer la même logique (p-value + z-score) à plusieurs paires simultanément (ex: XLF-XLK, XLC-XLF, XLI-XLK, etc.).\n","Nous allons ensuite agréger le PnL de chaque paire pour visualiser si la diversification améliore (ou non) le résultat global.\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["pairs_to_test = [\n","    (\"XLF\", \"XLK\"), \n","    (\"XLC\", \"XLF\"), \n","    (\"XLI\", \"XLK\"), \n","    # Ajoute éventuellement d'autres paires jugées co-intégrées\n","]\n","\n","def backtest_multiple_pairs(pairs, prices, p_threshold=0.10, z_threshold=2.0):\n","    \"\"\"\n","    On parcourt chaque paire, on génère df_signals_pv et on fait un mini_backtest.\n","    On retourne un DataFrame combiné du PnL cumulé en supposant \n","    qu'on additionne les PnL de chaque paire (sans gestion de risque globale).\n","    \"\"\"\n","    combined_pnl = pd.DataFrame()\n","    \n","    for (A, B) in pairs:\n","        if A not in prices.columns or B not in prices.columns:\n","            continue\n","        A_prices = prices[A].dropna()\n","        B_prices = prices[B].dropna()\n","        \n","        df_signals_pv = compute_signals_with_pval(\n","            A_prices, B_prices, \n","            window=30, \n","            z_threshold=z_threshold, \n","            p_threshold=p_threshold\n","        )\n","        df_bt_pv = mini_backtest(df_signals_pv, A_prices, B_prices)\n","        \n","        # on stocke le PnL sur la colonne \"PnL_<A>_<B>\"\n","        col_name = f\"PnL_{A}_{B}\"\n","        combined_pnl[col_name] = df_bt_pv['PnL']\n","    \n","    # On remplit les trous par 0\n","    combined_pnl = combined_pnl.fillna(method='ffill').fillna(0)\n","    \n","    # On crée une colonne \"TotalPnL\" qui somme toutes les paires\n","    combined_pnl['TotalPnL'] = combined_pnl.sum(axis=1)\n","    \n","    return combined_pnl\n","\n","df_multi = backtest_multiple_pairs(pairs_to_test, prices, p_threshold=0.10, z_threshold=2.0)\n","df_multi[['TotalPnL']].plot(figsize=(10,4), title=\"PnL total sur multi-paires\")\n","plt.show()\n","\n","df_multi.tail(10)\n"]},{"cell_type":"markdown","metadata":{},"source":["### C) Ajout d'un take-profit partiel\n","\n","Ici, nous allons modifier la fonction `mini_backtest` pour sortir une partie de la position si le z-score atteint un niveau extrême (disons ±2.5). L'objectif est de sécuriser une partie des gains. Cette logique reste simplifiée, mais illustre un mécanisme de money management basique.\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def mini_backtest_takeprofit(df_signals, seriesA, seriesB, \n","                             zscore_takeprofit=2.5):\n","    \"\"\"\n","    Ajout d'un take-profit partiel : \n","      - On suit la position existante (0, +1, -1)\n","      - Si on est +1 (LONG A, SHORT B) et que le z-score < -zscore_takeprofit,\n","        on sort la moitié de la position (ou la totalité), \n","        etc.\n","    NOTE : c'est un pseudo-code, à adapter selon la logique désirée.\n","    \"\"\"\n","    df_bt = pd.DataFrame({\n","        'Signal': df_signals['Signal'],\n","        'Zscore': df_signals['Zscore'],\n","        'PriceA': seriesA[df_signals.index],\n","        'PriceB': seriesB[df_signals.index]\n","    }).dropna()\n","    \n","    positions = []\n","    pnls = []\n","    current_position = 0\n","    entry_priceA = 0\n","    entry_priceB = 0\n","    cum_pnl = 0.0\n","    partial_closed = False  # Indique si le take-profit partiel a été exécuté\n","\n","    for i in range(len(df_bt)):\n","        signal_curr = df_bt['Signal'].iloc[i]\n","        z_curr = df_bt['Zscore'].iloc[i]\n","        priceA_curr = df_bt['PriceA'].iloc[i]\n","        priceB_curr = df_bt['PriceB'].iloc[i]\n","\n","        # Check changement de signal\n","        if signal_curr != current_position:\n","            # Fermer la position si existante\n","            if current_position != 0:\n","                if current_position == +1:\n","                    trade_pnl = (priceA_curr - entry_priceA) - (priceB_curr - entry_priceB)\n","                else:\n","                    trade_pnl = -(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB)\n","                cum_pnl += trade_pnl\n","            # Ouvrir nouvelle\n","            current_position = signal_curr\n","            partial_closed = False\n","            if current_position != 0:\n","                entry_priceA = priceA_curr\n","                entry_priceB = priceB_curr\n","        \n","        # Take-profit partiel si position +1 et z-score tombe < -2.5\n","        # ou si position -1 et z-score monte > +2.5\n","        # => on simule la fermeture de moitié de la position\n","        if current_position == +1 and not partial_closed:\n","            if z_curr < -zscore_takeprofit:\n","                # Fermer la moitié\n","                trade_pnl_half = 0.5 * ((priceA_curr - entry_priceA) - (priceB_curr - entry_priceB))\n","                cum_pnl += trade_pnl_half\n","                partial_closed = True\n","        elif current_position == -1 and not partial_closed:\n","            if z_curr > zscore_takeprofit:\n","                # Fermer la moitié\n","                trade_pnl_half = 0.5 * (-(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB))\n","                cum_pnl += trade_pnl_half\n","                partial_closed = True\n","        \n","        positions.append(current_position)\n","        pnls.append(cum_pnl)\n","    \n","    df_bt['Position'] = positions\n","    df_bt['PnL'] = pnls\n","    \n","    return df_bt\n","\n","# Test:\n","df_signals_pv = compute_signals_with_pval(A_prices, B_prices, window=30, z_threshold=2, p_threshold=0.10)\n","df_bt_takeprofit = mini_backtest_takeprofit(df_signals_pv, A_prices, B_prices, zscore_takeprofit=2.5)\n","\n","plt.figure(figsize=(10,4))\n","df_bt_takeprofit['PnL'].plot()\n","plt.title(\"PnL cumulatif (take-profit partiel)\")\n","plt.show()\n","\n","df_bt_takeprofit.tail(10)\n"]},{"cell_type":"markdown","metadata":{},"source":["### D) Mini risk management : stop-loss et cooldown\n","\n","Enfin, voici un exemple de fonction qui ajoute:\n","1. Un stop-loss si la position perd plus de 5 (ex. en PnL).\n","2. Un cooldown de 5 jours après la fermeture avant de rouvrir sur la même paire.\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def mini_backtest_risk(df_signals, seriesA, seriesB, \n","                       stop_loss=5.0,  # ex. stop-loss = -5\n","                       cooldown_days=5):\n","    \"\"\"\n","    On sort la position si la perte latente dépasse 'stop_loss'.\n","    On attend 'cooldown_days' barres après la fermeture d'une position avant de rouvrir.\n","    \"\"\"\n","    df_bt = pd.DataFrame({\n","        'Signal': df_signals['Signal'],\n","        'PriceA': seriesA[df_signals.index],\n","        'PriceB': seriesB[df_signals.index]\n","    }).dropna()\n","    \n","    positions = []\n","    pnls = []\n","    current_position = 0\n","    entry_priceA = 0\n","    entry_priceB = 0\n","    cum_pnl = 0.0\n","    \n","    # Gestion du cooldown\n","    days_in_cooldown = 0\n","    is_in_cooldown = False\n","\n","    for i in range(len(df_bt)):\n","        signal_curr = df_bt['Signal'].iloc[i]\n","        priceA_curr = df_bt['PriceA'].iloc[i]\n","        priceB_curr = df_bt['PriceB'].iloc[i]\n","\n","        if is_in_cooldown:\n","            days_in_cooldown += 1\n","            # On sort tout signal\n","            signal_curr = 0  \n","            if days_in_cooldown >= cooldown_days:\n","                is_in_cooldown = False\n","                days_in_cooldown = 0\n","        \n","        # Check changement de signal\n","        if signal_curr != current_position:\n","            # Fermer la position si existante\n","            if current_position != 0:\n","                if current_position == +1:\n","                    trade_pnl = (priceA_curr - entry_priceA) - (priceB_curr - entry_priceB)\n","                else:\n","                    trade_pnl = -(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB)\n","                cum_pnl += trade_pnl\n","                \n","                # On entre en cooldown quand on clôture une position\n","                is_in_cooldown = True\n","                days_in_cooldown = 0\n","            \n","            # Ouvrir (ou pas)\n","            if not is_in_cooldown and signal_curr != 0:\n","                current_position = signal_curr\n","                entry_priceA = priceA_curr\n","                entry_priceB = priceB_curr\n","            else:\n","                # Si cooldown, pas de nouvelle position\n","                current_position = 0\n","        \n","        else:\n","            # Vérifier le stop-loss\n","            if current_position == +1:\n","                unrealized_pnl = (priceA_curr - entry_priceA) - (priceB_curr - entry_priceB)\n","                if unrealized_pnl <= -stop_loss:\n","                    # Stop-loss\n","                    cum_pnl += unrealized_pnl\n","                    current_position = 0\n","                    is_in_cooldown = True\n","                    days_in_cooldown = 0\n","            elif current_position == -1:\n","                unrealized_pnl = -(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB)\n","                if unrealized_pnl <= -stop_loss:\n","                    # Stop-loss\n","                    cum_pnl += unrealized_pnl\n","                    current_position = 0\n","                    is_in_cooldown = True\n","                    days_in_cooldown = 0\n","\n","        positions.append(current_position)\n","        pnls.append(cum_pnl)\n","    \n","    df_bt['Position'] = positions\n","    df_bt['PnL'] = pnls\n","    return df_bt\n","\n","# Test\n","df_signals_pv = compute_signals_with_pval(A_prices, B_prices, window=30, z_threshold=2, p_threshold=0.10)\n","df_bt_risk = mini_backtest_risk(df_signals_pv, A_prices, B_prices, stop_loss=5.0, cooldown_days=5)\n","\n","plt.figure(figsize=(10,4))\n","df_bt_risk['PnL'].plot()\n","plt.title(\"PnL cumulatif (Stop-loss=5, cooldown=5j)\")\n","plt.show()\n","\n","df_bt_risk.tail(10)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 1) Tester différents \"window\" pour le calcul du z-score\n","\n","Nous allons comparer l'impact de différentes longueurs de fenêtre (rolling window) pour le calcul du z-score (ex. 20, 30, 40).  \n","L'objectif est de voir si un z-score calculé sur une fenêtre plus courte (20) est plus réactif et/ou plus rentable qu'un z-score sur une fenêtre plus longue (40).  \n","\n","- **Fenêtre courte** : davantage de signaux, potentiellement plus de bruit.  \n","- **Fenêtre longue** : signaux plus rares, mais peut-être plus robustes.  \n","\n","Ensuite, nous observerons la colonne `FinalPnL` pour chaque fenêtre testée.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_different_zscore_windows(seriesA, seriesB, windows=[20,30,40], z_threshold=2.0, p_threshold=0.10):\n","    \"\"\"\n","    Compare l'impact de différentes tailles de fenêtre (rolling) \n","    pour le calcul du z-score, avec un threshold fixe.\n","    \"\"\"\n","    results = []\n","    for w in windows:\n","        df_signals_pv = compute_signals_with_pval(\n","            seriesA, seriesB,\n","            window=w,         # On varie ici\n","            z_threshold=z_threshold, \n","            p_threshold=p_threshold\n","        )\n","        df_bt_pv = mini_backtest(df_signals_pv, seriesA, seriesB)\n","        final_pnl = df_bt_pv['PnL'].iloc[-1] if len(df_bt_pv) > 0 else 0\n","        results.append((w, final_pnl))\n","    \n","    df_res = pd.DataFrame(results, columns=[\"ZscoreWindow\", \"FinalPnL\"])\n","    return df_res\n","\n","windows_test = [20, 30, 40]\n","df_win_test = test_different_zscore_windows(A_prices, B_prices, windows=windows_test, z_threshold=2.0)\n","df_win_test\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2) Ajouter un \"time stop\" à la stratégie\n","\n","Ici, nous introduisons la notion de *time stop* :  \n","- Si une position reste ouverte plus de `max_bars_in_position` barres (jours), on la clôture de force, peu importe le z-score.  \n","- L'idée est d'éviter de maintenir une position indéfiniment dans l'espoir que l'écart revienne, alors que la co-intégration peut ne plus être valide.\n","\n","Nous conservons le reste de la logique :  \n","- On ouvre la position quand le z-score franchit ±threshold (et p-value < threshold).  \n","- On la ferme si le z-score repasse le signal ou qu'on dépasse la durée maximale autorisée en position.\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def mini_backtest_time_stop(df_signals, seriesA, seriesB, max_bars_in_position=20):\n","    \"\"\"\n","    Identique à mini_backtest, mais on ajoute :\n","      - on compte le nombre de barres passées en position\n","      - si on dépasse max_bars_in_position, on sort de force\n","    \"\"\"\n","    df_bt = pd.DataFrame({\n","        'Signal': df_signals['Signal'],\n","        'PriceA': seriesA[df_signals.index],\n","        'PriceB': seriesB[df_signals.index]\n","    }).dropna()\n","\n","    positions = []\n","    pnls = []\n","    current_position = 0\n","    entry_priceA = 0\n","    entry_priceB = 0\n","    cum_pnl = 0.0\n","    bars_in_position = 0\n","\n","    for i in range(len(df_bt)):\n","        signal_curr = df_bt['Signal'].iloc[i]\n","        priceA_curr = df_bt['PriceA'].iloc[i]\n","        priceB_curr = df_bt['PriceB'].iloc[i]\n","\n","        if signal_curr != current_position:\n","            # Fermer si besoin\n","            if current_position != 0:\n","                if current_position == +1:\n","                    trade_pnl = (priceA_curr - entry_priceA) - (priceB_curr - entry_priceB)\n","                else:\n","                    trade_pnl = -(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB)\n","                cum_pnl += trade_pnl\n","            # Ouvrir la nouvelle\n","            current_position = signal_curr\n","            bars_in_position = 0\n","            if current_position != 0:\n","                entry_priceA = priceA_curr\n","                entry_priceB = priceB_curr\n","        else:\n","            # si on est en position, incrémenter le compteur\n","            if current_position != 0:\n","                bars_in_position += 1\n","                if bars_in_position > max_bars_in_position:\n","                    # On force la sortie\n","                    if current_position == +1:\n","                        trade_pnl = (priceA_curr - entry_priceA) - (priceB_curr - entry_priceB)\n","                    else:\n","                        trade_pnl = -(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB)\n","                    cum_pnl += trade_pnl\n","                    current_position = 0\n","\n","        positions.append(current_position)\n","        pnls.append(cum_pnl)\n","    \n","    df_bt['Position'] = positions\n","    df_bt['PnL'] = pnls\n","    return df_bt\n","\n","# Test rapide:\n","df_signals_time = compute_signals_with_pval(A_prices, B_prices, window=30, z_threshold=2, p_threshold=0.10)\n","df_bt_time = mini_backtest_time_stop(df_signals_time, A_prices, B_prices, max_bars_in_position=20)\n","df_bt_time['PnL'].plot(title=\"PnL (Time Stop = 20 barres)\", figsize=(10,4))\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3) Exprimer le PnL en pourcentage du capital\n","\n","Pour mieux interpréter la performance, nous allons convertir le PnL absolu en pourcentage du capital initial (ex. 100 000\\$).  \n","- Dans notre version simplifiée, +1 de PnL ≈ +1 \\$, car nous simulons l'achat d'1 share de A et la vente d'1 share de B.  \n","- Dans une approche plus réaliste, il faudrait dimensionner la position en fonction du prix, de la volatilité, etc.  \n","\n","Cette étape sert surtout à donner un ordre de grandeur du rendement (PnL%) plutôt que de simples montants bruts.\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def mini_backtest_in_percentage(df_signals, seriesA, seriesB, capital=100000):\n","    \"\"\"\n","    Convertit le PnL en % du capital initial, \n","    en supposant qu'un PnL de +1 = +1$ dans la logique simplifiée actuelle.\n","    \n","    On suppose qu'on achète 1 share de A / short 1 share de B (ou l'inverse).\n","    => En réalité, on voudrait calibrer la taille de position pour être plus cohérent.\n","    \"\"\"\n","    df_bt = pd.DataFrame({\n","        'Signal': df_signals['Signal'],\n","        'PriceA': seriesA[df_signals.index],\n","        'PriceB': seriesB[df_signals.index]\n","    }).dropna()\n","\n","    positions = []\n","    pnls = []\n","    current_position = 0\n","    entry_priceA = 0\n","    entry_priceB = 0\n","    cum_pnl = 0.0\n","\n","    for i in range(len(df_bt)):\n","        signal_curr = df_bt['Signal'].iloc[i]\n","        priceA_curr = df_bt['PriceA'].iloc[i]\n","        priceB_curr = df_bt['PriceB'].iloc[i]\n","\n","        if signal_curr != current_position:\n","            if current_position != 0:\n","                # Fermer\n","                if current_position == +1:\n","                    trade_pnl = (priceA_curr - entry_priceA) - (priceB_curr - entry_priceB)\n","                else:\n","                    trade_pnl = -(priceA_curr - entry_priceA) + (priceB_curr - entry_priceB)\n","                cum_pnl += trade_pnl\n","            current_position = signal_curr\n","            if current_position != 0:\n","                entry_priceA = priceA_curr\n","                entry_priceB = priceB_curr\n","        \n","        positions.append(current_position)\n","        pnls.append(cum_pnl)\n","    \n","    df_bt['Position'] = positions\n","    df_bt['PnL'] = pnls\n","    # Conversion en % du capital\n","    df_bt['PnLPct'] = (df_bt['PnL'] / capital) * 100\n","    return df_bt\n","\n","df_signals_pct = compute_signals_with_pval(A_prices, B_prices, window=30, z_threshold=2, p_threshold=0.10)\n","df_bt_pct = mini_backtest_in_percentage(df_signals_pct, A_prices, B_prices, capital=100000)\n","df_bt_pct[['PnL','PnLPct']].tail(10)\n"]}],"metadata":{"kernelspec":{"display_name":"Foundation-Py-Default","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":2}
